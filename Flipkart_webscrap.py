# -*- coding: utf-8 -*-
"""Untitled40.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xVUxN9cInnrVJ2-TTqN08oPBgUw6PN5_
"""

# Install required libraries (only needed once in Colab)
!pip install requests beautifulsoup4 lxml

import pandas as pd
import requests
from bs4 import BeautifulSoup
import time

# Data storage lists
Product_name = []
Prices = []
Description = []
Reviews = []
Discount = []

# Headers to mimic browser
headers = {
    "User-Agent": "Mozilla/5.0"
}

# Loop through multiple pages
for page in range(1, 5):
    url = f"https://www.flipkart.com/search?q=mobiles&page={page}"
    print(f"Scraping page {page}...")
    r = requests.get(url, headers=headers)
    soup = BeautifulSoup(r.text, "lxml")

    box = soup.find_all("div", class_="tUxRFH")

    for product in box:
        name = product.find("div", class_="KzDlHZ")
        Product_name.append(name.text if name else "N/A")

        price = product.find("div", class_="Nx9bqj _4b5DiR")
        Prices.append(price.text if price else "N/A")

        desc = product.find("ul", class_="G4BRas")
        Description.append(desc.text if desc else "N/A")

        review = product.find("div", class_="XQDdHH")
        Reviews.append(review.text if review else "N/A")

        discount = product.find("div", class_="UkUFwK")
        Discount.append(discount.text if discount else "N/A")

    time.sleep(1)  # Prevent rapid requests

# Create DataFrame and save to CSV
df = pd.DataFrame({
    "Product Name": Product_name,
    "Price": Prices,
    "Description": Description,
    "Review": Reviews,
    "Discount": Discount
})

df.to_csv("flipkart_mobiles.csv", index=False)
print("CSV file saved successfully.")